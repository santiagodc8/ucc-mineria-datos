{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Week 14 Workshop: Build Your First Machine Learning Model\n",
    "\n",
    "## Water Consumption Dataset\n",
    "\n",
    "### Objectives\n",
    "1. Prepare data for machine learning\n",
    "2. Train a Decision Tree model (regression)\n",
    "3. Evaluate performance and detect overfitting\n",
    "4. Experiment with max_depth to find the best model\n",
    "\n",
    "### Duration: 2 hours\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell to load all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Water Consumption dataset from datos.gov.co\n",
    "url = \"https://www.datos.gov.co/resource/k9gy-47jj.csv?$limit=10000\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "print(f\"\\nColumns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Data Preparation\n",
    "\n",
    "Prepare your data for modeling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 1.1 Identify Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify column types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Numeric columns:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"  - {col}: min={df[col].min():.2f}, max={df[col].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 1.2 Select Target Variable\n",
    "\n",
    "For regression, choose a continuous numeric column (e.g., consumption amount)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Select the target column\n",
    "consumption_candidates = [col for col in numeric_cols if any(x in col.lower() for x in ['consumo', 'consumption', 'valor', 'cantidad', 'total'])]\n",
    "print(f\"Potential target columns: {consumption_candidates}\")\n",
    "\n",
    "# Select target (UPDATE this based on your dataset)\n",
    "target_col = ___  # e.g., consumption_candidates[0]\n",
    "\n",
    "print(f\"\\nSelected target: {target_col}\")\n",
    "print(df[target_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 1.3 Select Features and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select feature columns (numeric, excluding target and IDs)\n",
    "feature_cols = [col for col in numeric_cols if col != target_col]\n",
    "\n",
    "id_patterns = ['id', 'codigo', 'code', 'key']\n",
    "feature_cols = [col for col in feature_cols if not any(p in col.lower() for p in id_patterns)]\n",
    "\n",
    "print(f\"Selected features: {feature_cols}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values and prepare X, y\n",
    "df_clean = df[feature_cols + [target_col]].dropna()\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y = df_clean[target_col]\n",
    "\n",
    "print(f\"Rows before cleaning: {len(df)}\")\n",
    "print(f\"Rows after cleaning: {len(df_clean)}\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 1.4 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Decision Tree Regressor\n",
    "\n",
    "Build your first model using the sklearn pattern: Create -> Fit -> Predict -> Evaluate.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 2.1 Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create and train a Decision Tree Regressor\n",
    "\n",
    "# Step 1: Create the model (use max_depth=5 to prevent overfitting)\n",
    "model = ___\n",
    "\n",
    "# Step 2: Train the model\n",
    "___\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred = ___\n",
    "\n",
    "print(\"Model trained and predictions made!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 2.2 Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== DECISION TREE RESULTS ===\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 2.3 Check for Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare train vs test performance\n",
    "y_pred_train = model.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "\n",
    "print(f\"Training R-squared: {r2_train:.4f}\")\n",
    "print(f\"Test R-squared:     {r2:.4f}\")\n",
    "print(f\"Gap:                {r2_train - r2:.4f}\")\n",
    "\n",
    "if r2_train - r2 > 0.1:\n",
    "    print(\"\\nWarning: Possible overfitting! Consider reducing max_depth.\")\n",
    "else:\n",
    "    print(\"\\nGood: No significant overfitting detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 2.4 Visualize: Actual vs Predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted scatter plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(y_test, y_pred, alpha=0.5, color='steelblue')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "ax.set_xlabel('Actual Values', fontsize=12)\n",
    "ax.set_ylabel('Predicted Values', fontsize=12)\n",
    "ax.set_title(f'Decision Tree (max_depth=5): Actual vs Predicted\\nR-squared = {r2:.4f}', fontsize=14)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Experiment with max_depth\n",
    "\n",
    "Try different tree depths to find the best balance between accuracy and overfitting.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Try different max_depth values\n",
    "# For each depth, record train R-squared, test R-squared, and the gap\n",
    "\n",
    "depths = [2, 3, 5, 7, 10, 15, 20, None]  # None = unlimited\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    dt = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    r2_tr = r2_score(y_train, dt.predict(X_train))\n",
    "    r2_te = r2_score(y_test, dt.predict(X_test))\n",
    "    \n",
    "    results.append({\n",
    "        'max_depth': str(depth) if depth else 'None',\n",
    "        'R2_train': r2_tr,\n",
    "        'R2_test': r2_te,\n",
    "        'gap': r2_tr - r2_te\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"=== DEPTH COMPARISON ===\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Plot the overfitting curve\n",
    "# X-axis: max_depth, Y-axis: R-squared (two lines: train and test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x_labels = results_df['max_depth'].tolist()\n",
    "x_pos = range(len(x_labels))\n",
    "\n",
    "ax.plot(x_pos, results_df['R2_train'], 'o-', color='steelblue', linewidth=2, label='Train R-squared')\n",
    "ax.plot(x_pos, results_df['R2_test'], 's-', color='coral', linewidth=2, label='Test R-squared')\n",
    "\n",
    "ax.set_xticks(list(x_pos))\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_xlabel('max_depth', fontsize=12)\n",
    "ax.set_ylabel('R-squared', fontsize=12)\n",
    "ax.set_title('Overfitting Curve: Train vs Test R-squared', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "# Shade the gap\n",
    "ax.fill_between(x_pos, results_df['R2_train'], results_df['R2_test'], alpha=0.2, color='red', label='Overfitting gap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nThe gap between train and test grows as depth increases = overfitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "### Depth Analysis\n",
    "\n",
    "**Write your analysis below:**\n",
    "\n",
    "*Which max_depth gives the best test R-squared with acceptable overfitting?*\n",
    "\n",
    "*YOUR ANALYSIS HERE*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Decision Tree Classifier (Bonus)\n",
    "\n",
    "Convert the problem to classification and try a DecisionTreeClassifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create consumption categories based on quartiles\n",
    "def categorize(value, thresholds):\n",
    "    if value < thresholds[0]:\n",
    "        return 'Low'\n",
    "    elif value < thresholds[1]:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "thresholds = [y.quantile(0.33), y.quantile(0.66)]\n",
    "print(f\"Thresholds: Low < {thresholds[0]:.2f} < Medium < {thresholds[1]:.2f} < High\")\n",
    "\n",
    "y_cat = y.apply(lambda x: categorize(x, thresholds))\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(y_cat.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Train a DecisionTreeClassifier\n",
    "\n",
    "# Split for classification\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X, y_cat, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create and train classifier\n",
    "clf = ___\n",
    "___\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_c = ___\n",
    "accuracy = accuracy_score(y_test_c, y_pred_c)\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting (classification)\n",
    "train_accuracy = accuracy_score(y_train_c, clf.predict(X_train_c))\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Test accuracy:     {accuracy:.2%}\")\n",
    "print(f\"Gap:               {train_accuracy - accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Interpretation and Reflection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from the best model\n",
    "# Decision Trees automatically calculate feature importance\n",
    "\n",
    "# Use the best regression model (retrain with best depth if needed)\n",
    "best_depth = 5  # UPDATE based on your Part 3 analysis\n",
    "best_model = DecisionTreeRegressor(max_depth=best_depth, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "print(importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.barh(importance['feature'], importance['importance'], color='steelblue')\n",
    "ax.set_xlabel('Importance', fontsize=12)\n",
    "ax.set_ylabel('Feature', fontsize=12)\n",
    "ax.set_title('Decision Tree: Feature Importance', fontsize=14)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "**Answer these questions:**\n",
    "\n",
    "### 1. Best max_depth\n",
    "*Which max_depth gave you the best test R-squared without excessive overfitting? Why?*\n",
    "\n",
    "*YOUR ANSWER HERE*\n",
    "\n",
    "### 2. Model Quality\n",
    "*Is the R-squared acceptable? What does it mean for your predictions?*\n",
    "\n",
    "*YOUR ANSWER HERE*\n",
    "\n",
    "### 3. Feature Importance\n",
    "*Which features are most important? Does this make sense from a domain perspective?*\n",
    "\n",
    "*YOUR ANSWER HERE*\n",
    "\n",
    "### 4. Next Steps\n",
    "*What would you try next to improve the model? (e.g., more features, different model, feature engineering)*\n",
    "\n",
    "*YOUR ANSWER HERE*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Checklist\n",
    "\n",
    "Before submitting, verify:\n",
    "\n",
    "- [ ] All cells have been executed (Kernel > Restart & Run All)\n",
    "- [ ] Part 1: Data is properly prepared\n",
    "- [ ] Part 2: Decision Tree trained and evaluated\n",
    "- [ ] Part 3: Multiple depths tested and overfitting curve plotted\n",
    "- [ ] Part 4 (Bonus): Classification attempted\n",
    "- [ ] Part 5: Reflection questions answered\n",
    "\n",
    "---\n",
    "\n",
    "*Week 14 Workshop - Data Analytics Course - Universidad Cooperativa de Colombia*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
